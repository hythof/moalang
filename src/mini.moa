# TODO:
# - make a helper for patterns of `if ...: return ...`
# - make a helper to patterns of like until, quote functions
# - make a helper to patterns of like breaklines function
struct Token:
  code string
  type string
  line int
  column int

adt Node:
  value Token
  list []Node

def tokenize src:
  let id "abcdefghijklmnopqrstuvxwyz_"
  let num "0123456789"
  let idnum id + num
  let singles "():."
  let symbols "+ - * / =".split " "
  var tokens []
  var line 1
  var column 1
  var pos 0

  def push fragment type:
    tokens.push Token(fragment type line column)
    column += fragment.replace("\n" "").size

  def until f:
    s = ""
    while pos < src.size && f src.at(pos):
      s += src.at pos
      pos += 1
    pos -= 1
    s

  def quote q:
    pos += 1
    let s q + until(c => c != q) + q
    pos += 1
    s

  def breaklines:
    s = ""
    while pos < src.size && src.at(pos) == "\n":
      pos += 1
      line += 1
      s = "\n" + until(c => c == " ")
    column = 1
    push s ""

  def consume:
    var c src.at pos
    if c == "\\":
      pos += 1
      c = src.at pos
      if c == "n": c = "\n"
      if c == "t": c = "\t"
      if c == "\\": c = "\\"
    c

  while pos < src.size:
    let c consume()
    if c == `"`: push quote(c) "string"
    if c == `'`: push quote(c) "string"
    if c == " ": column += until(c => c == " ").size
    if c == "\n": breaklines()
    if singles.contains c: push c ""
    if symbols.contains c: push until(symbols.contains) ""
    if id.contains c: push until(idnum.contains) ""
    if num.contains c: push until(num.contains) "int"
    pos += 1
  tokens

def parse tokens:
  var pos 0
  def lines indent: sepby1 line (t => t == indent)
  def line: many1 unit
  def unit:
    let token tokens.at pos
    pos += 1
    if token.code == "(": return until c => c == ")" []
    if token.code == "[": return until c => c == "]" []
    if token.code.at(token.code.size - 1) == "(": return until c => c == ")" [token]
    if token.code == ":":
      let next tokens.at pos
      if next.code.at(0) == "\n": return lines(next)
      return line()
    Node.value token

  # helper methods
  def breakline: pos += 1
  def until f a: many_rec assert(f(tokens.at(pos).code) unit()) a
  def sepby1 f g: many_rec () => do(f() g()) [f()]
  def many_rec f acc: catch(many_rec(f acc.append(f())) _ => Node.list(acc))
  def many1 f: many_rec f [f()]
  def many f: many_rec f []
  lines("\n")

def inference nodes:
  io.dump nodes
  "int"

def compile_to_js nodes:
  nodes

def main:
  let src io.stdin
  let tokens tokenize src
  let nodes parse tokens
  let js compile_to_js nodes
  io.print js

test t:
  t.eq [Token("def" "" 1 1) Token("f" "" 1 5) Token(":" "" 1 6) Token("\n  " "" 2 1) Token("1" "int" 2 3)] tokenize(`def f:\n  1`)
  t.eq ["def" "func" "arg1" ":" "\n  " "f" "(" "arg1" "+" "10" ")" "==" `"hi"` "." "size"] tokenize(`def func arg1:\n  f (arg1 + 10) == "hi".size`).map(t => t.code)

test t:
  def simplify node:
    match node:
      value v: v.code
      list l: "(" + l.map(simplify).join(" ") + ")"
  t.eq "((def main (1)))" simplify(parse(tokenize("def main: 1")))

test t:
  def type src:
    inference(parse(tokenize(src)))
  t.eq "int" type("1")
