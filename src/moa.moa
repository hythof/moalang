help = "Moa is a tool for managing Moa source code.

Usage:
  moa <command> [arguments]

The commands are:
  moa                # launch repl
  moa build          # compile to an executable file without test
  moa format file    # format a file
  moa help [topic]   # for more info about topic
  moa js file        # compile to JavaScript
  moa lint file      # report likely mistakes
  moa run [exp]      # run Moa program
  moa test [regexps] # run tests
  moa version        # print Moa version"

def main io:
  match io.argv:
    []: repl io
    ["build"]      : io.puts "Not implemented yet"
    ["format" file]: io.puts "Not implemented yet"
    ["help" topic] : io.puts "Not implemented yet"
    ["js" file]    : io.puts "Not implemented yet"
    ["lint" file]  : io.puts "Not implemented yet"
    ["run"]        : io.puts "Not implemented yet"
    ["run" exp]    : io.puts "Not implemented yet"
    ["test"]       : io.puts "Not implemented yet"
    ["test" target]: io.puts "Not implemented yet"
    ["version"]    : io.puts "moa v0.1"
    _              : io.puts help

def repl io:
  io.puts "repl"

def compile_to_js source:
  "const main = io => log(io)"

class type:
  name string
  params list[type]

class token:
  text string
  indent int
  lineno int
  column int
  args list[token]
  type type

tundef = type "" []

def parse source:
  tokens =
    regexp = r"((?:!=)|[()\[\]{}!]|(?:-?[0-9]+(?:\.[0-9]+)?)|[ \t\n]+(?:#[^\n]*|[ \t\n]+)*|\"[^]*?(?<!\\)\"|[A-Za-z0-9_]+|#[^\n]*)"
    indent = 0
    lineno = 1
    column = 1
    source.rsplit(regexp).fmap text =>
      guard text == "": []
      guard text.has("\n"):
        indent := text.split("\n")[-1].size
        lineno += text.split("\n").size - 1
        column := indent
        []
      guard text.match(r"^[ \t#]"): []
      t = token text indent lineno column [] tundef
      column += text.size
      t
  guard tokens.size == 0: token "__statement" 0 0 0 [] tundef []
  def rename t text args:
    token(text t.indent t.lineno t.column args t.type)
  def apply t args:
    guard args.size == 0: rename t "__apply" [t]
    guard t.args.size > 0: rename t "__apply" [t] ++ args
    rename t t.text args
  def call t:
    guard t.args.size == 0: rename(t "__apply" [t])
    t
  pos = 0
  def end_by forward check:
    def loop a:
      guard pos >= tokens.size: a
      guard check(tokens[pos]): a
      loop a ++ [forward()]
    loop []
  def until end:
    end_by parse_exp t =>
      guard t.text == end:
        pos += 1
        true
      false
  def parse_unit:
    def consume:
      t = tokens[pos]
      pos += 1
      guard t.text == "(": until(")")[0]
      guard t.text == "[": call(rename(t "list" until("]")))
      guard t.text == ":": parse_block()
      t
    def suffix x:
      guard pos >= tokens.size: x
      t = tokens[pos]
      guard t.text == ".":
        pos += 2
        suffix apply(t [x tokens[pos - 1]])
      guard t.text == ",":
        remain = end_by consume t =>
          guard t.text == ",":
            pos += 1
            false
          true
        guard pos < tokens.size && tokens[pos].text == "=>": alambda [t] ++ remain parse_exp()
        suffix rename(t "tuple" [x] ++ remain)
      guard t.text == "(":
        pos += 1
        suffix apply(x until(")"))
      guard t.text == "[":
        pos += 1
        suffix rename(t "__index" [x] ++ until("]"))
      x
    suffix consume()
  def parse_exp:
    lhs = parse_unit()
    guard pos >= tokens.size: lhs
    guard lhs.text == "!": apply lhs [parse_unit()]
    lop = tokens[pos]
    op2s = ", * ** / // % + ++ - >> << ^ & | := += -= *= /= %= **= < <= > >= == != === !== <=> && || =".split " "
    guard op2s.has(lop.text):
      pos += 1
      rhs_first_text = tokens[pos].text
      rhs = parse_exp()
      guard rhs_first_text != "(" && op2s.has(rhs.text) && op2s.index(lop.text) < op2s.index(rhs.text):
        rename rhs rhs.text [apply(lop [lhs rhs.args[0]]) rhs.args[1]]
      apply lop [lhs rhs]
    guard lop.text == "=>":
      pos += 1
      apply lop [lhs parse_exp()]
    lhs
  def parse_block:
    guard tokens[pos - 1].indent < tokens[pos].indent: parse_statement()
    parse_line()
  def parse_line:
    first_pos = pos
    first_token = tokens[pos]
    guard first_token.text == "def":
      pos += 1
      name = tokens[pos]
      def take_args a:
        pos += 1
        guard pos >= tokens.size: a
        guard tokens[pos].text == ":": a
        take_args a ++ tokens[pos]
      args = take_args []
      body = token "=>" 0 0 0 args ++ [parse_exp()] tundef []
      rename first_token "=" [name] ++ body
    guard pos + 1 < tokens.size && tokens[pos+1].text == "=":
      eq = tokens[pos+1]
      pos += 2
      apply eq [first_token parse_exp()]
    def loop a:
      guard pos >= tokens.size || tokens[pos].lineno != first_token.lineno:
        guard a.size == 1: a[0]
        apply a[0] a.slice(1)
      loop a ++ [parse_exp()]
    loop []
  def parse_statement:
    current_indent = tokens[pos].indent
    lines = end_by(parse_line t => t.indent != current_indent)
    guard lines.size == 1: lines[0]
    token "__statement" 0 0 0 lines tundef []
  parse_statement()

def infer root:
  id = 0
  def new_var:
    type (id+=1).string []
  def new_more t:
    type "__more" [t]
  def tfunc types:
    type "" types
  tv1 = new_var()
  tbool = type "bool" []
  tint = type "int" []
  tfloat = type "float" []
  tstring = type "string" []
  tlist = tfunc [new_more(tv1) type("list" [tv1])]
  tprop = dict("list" dict("size" _ => tint))
  def analyze node ng tenv:
    def squash_type t:
      t.params = squash_params t.params
      t
    def squash_params a:
      guard a.size >= 2 && a[0].name == "__more": squash_params a.slice(1)
      a
    def try_unify a b:
      def copy a b:
        b.name := a.name
        b.params := a.params
        true
      guard a.name.match(r"^[0-9]"): copy b a
      guard b.name.match(r"^[0-9]"): copy a b
      guard a.name == "__more": try_unify a.params[0] b
      guard b.name == "__more": try_unify a b.params[0]
      a == b
    def unify a b:
      guard try_unify(a b): a
      error "type miss match"
    def apply a b:
      guard a.size == 0: error "internal applying error"
      guard b.size == 0:
        params = squash_params a
        guard params.size == 1: params[0]
        error "wrong number of arguments"
      guard try_unify(a[0] b[0]):
        guard a[0].name == "__more":
          apply a b.slice(1)
        apply a.slice(1) b.slice(1)
      guard a[0].name == "__more":
        apply a.slice(1) b.slice(1)
      error "type miss match"
    def inf node:
      def inf_text s:
        guard s.match(r"^[0-9]+\.[0-9]+$"): tfloat
        guard s.match(r"^[0-9]+$"): tint
        guard s.match(r"^[A-Za-z_]"): tenv[s]
        guard s.starts("\""): tstring
        error s
      guard node.args.size == 0: inf_text node.text
      guard node.text == "__apply":
        ts = node.args.map(inf)
        apply ts[0].params ts.slice(1)
      guard node.text == "=>":
        argst = node.args.slice(0 -1).map(t => t.text, new_var())
        new_tenv = tenv ++ argst.dict()
        new_ng = ng ++ set(argst.map(at => at.0))
        tfunc argst.map(at => at.1) ++ [analyze(node.args[-1] new_ng new_tenv).type]
      guard node.text == ".":
        t = inf node.args[0]
        tprop[t.name][node.args[1].text](node.type.params)
      apply tenv[node.text].params node.args.map(inf)
    node.type := inf(node)
    node
  analyze root set() dict(
    "!" tfunc([tbool tbool])
    "+" tfunc([tint tint tint])
    "-" tfunc([tint tint tint])
    "*" tfunc([tint tint tint])
    "/" tfunc([tint tint tint])
    "list" tlist
    "true" tbool
    "false" tbool)

test t "parser":
  def show_token t:
    guard t.text == "__apply": show_token(t.args[0]) ++ "(" ++ t.args.slice(1).map(show_token).join(" ") ++ ")"
    guard t.text == "__statement": t.args.map(show_token).join("; ")
    guard t.text == "=": show_token(t.args[0]) ++ " = " ++ t.args.slice(1).map(show_token).join(" ")
    guard t.text == "=>": "(" ++ t.args.slice(0 -1).map(show_token).join(" ") ++ " => " ++ show_token(t.args[-1]) ++ ")"
    guard t.args.size == 0: t.text
    t.text ++ "(" ++ t.args.map(show_token).join(" ") ++ ")"

  def show_type t:
    def stringify t:
      guard t.params.size == 0: t.name
      guard t.name == "": "(" ++ t.params.map(stringify).join(" ") ++ ")"
      t.name ++ "[" ++ t.params.map(stringify).join(" ") ++ "]"
    def simplify t:
      g = dict()
      t.replace r"[0-9]+" p =>
        guard g.has(p): g.get(p)
        g[p] = g.size.string
    simplify(stringify(t))

  def test_parser expectation source:
    t.eq expectation show_token(parse(source)) source
  test_parser "+(*(1 2) 3)" "1 * 2 + 3"

  # primitives
  test_parser "1" "1"
  test_parser "1.1" "1.1"
  test_parser "id" "id"
  test_parser "\"hi\"" "\"hi\""
  test_parser "\"\\t\"" "\"\\t\""
  test_parser "true" "true"
  test_parser "tuple(a b)" "a,b"
  test_parser "tuple(a b c)" "a,b,c"
  test_parser "(a => a)" "a => a"
  # container
  test_parser "list()" "[]"
  test_parser "list(1 2)" "[1 2]"
  # property access
  test_parser ".(a b)" "a.b"
  test_parser ".(a b)(c)" "a.b c"
  test_parser ".(list() a)" "[].a"
  test_parser "(p => +(.(p x) .(p y)))" "p => p.x + p.y"
  # single operator
  test_parser "!(true)" "!true"
  # binary operators
  test_parser "+(1 2)" "1 + 2"
  test_parser "+(1 +(2 3))" "1 + 2 + 3"
  test_parser "+(*(1 2) 3)" "1 * 2 + 3"
  test_parser "!=(1 1)" "1 != 1"
  test_parser "+=(a 1)" "a += 1"
  test_parser "+=(a +(1 2))" "a += 1 + 2"
  # parentheses
  test_parser "1" "(1)"
  test_parser "+(+(1 2) 3)" "(1 + 2) + 3"
  test_parser "*(1 +(2 3))" "1 * (2 + 3)"
  test_parser "*(+(1 2) 3)" "(1 + 2) * 3"
  # definition
  test_parser "a = 1" "a = 1"
  test_parser "f = (a => a)" "def f a: a"
  test_parser "a = +(1 2)" "a = 1 + 2"
  test_parser "f = (a => a)" "def f a:\n  a"
  test_parser "f = (a => a; b)" "def f a:\n  a\n  b"
  test_parser "f = (a => b = 1; +(a b))" "def f a:\n  b = 1\n  a + b"
  # function call
  test_parser "f()" "f()"
  test_parser "f(1)" "f(1)"
  test_parser "f(+(1 2))" "f(1 + 2)"
  # method call
  test_parser ".(f m)" "f.m"
  test_parser ".(f 1)" "f.1"
  test_parser ".(f m)()" "f.m()"
  test_parser ".(f m)(a)" "f.m(a)"
  test_parser ".(f m)(a b)" "f.m(a b)"
  # index access
  test_parser "__index(x 1)" "x[1]"
  test_parser "__index(x 1 2)" "x[1 2]"
  # steps
  test_parser "a; b" "a\nb"
  test_parser "a(b); c" "a b\nc"
  test_parser "a; b(c)" "a\nb c"
  # block
  test_parser "a(b)"      "a: b"
  test_parser "a(b(c))"   "a: b c"
  test_parser "a(b c)"    "a b: c"
  test_parser "a(b c(d))" "a b: c d"
  # indent
  test_parser "a(b)"            "a:\n  b"
  test_parser "a(b); c"         "a:\n  b\nc"
  test_parser "a(b; c)"         "a:\n  b\n  c"
  test_parser "a(b(c))"         "a:\n  b:\n    c"
  test_parser "a(b c)"          "a b:\n  c"
  test_parser "a(b c(d))"       "a b:\n  c d"
  test_parser "a(b c; d)"       "a b:\n  c\n  d"
  test_parser "a(b c(d); e)"    "a b:\n  c d\n  e"
  test_parser "a(b c(d e))"     "a b:\n  c d:\n  e"
  test_parser "a(b c(d e(f)))"  "a b:\n  c d:\n  e f"
  # comment
  test_parser "a = 1" "#comment\na = 1 # comment\n#comment"
  test_parser "a(b; c)" "a:\n  #comment\n  b\n  #comment\n  c\n  # comment"
  # combinations
  test_parser "!(a(b))" "!a(b)"
  test_parser "+(a(b) c)" "a(b) + c"
  test_parser ".(__index(a b) c)" "a[b].c"
  test_parser ".(__index(a b) c)(d)" "a[b].c(d)"
  # edge case
  test_parser "1" "1\n"
  test_parser "" " "
  test_parser "" "\n"

  def test_show expectation ty:
    t.eq expectation show_type(ty)
  ta = type "a" []
  test_show "a" ta
  test_show "(a a)" type("" [ta ta])
  test_show "t[a a]" type("t" [ta ta])

  def test_infer expectation source:
    node = parse source
    t.eq expectation show_type(infer(node).type) source ++ " -> " + show_token(node)
  # primitives
  test_infer "bool" "true"
  test_infer "bool" "false"
  test_infer "int" "1"
  test_infer "float" "1.1"
  test_infer "string" "\"s\""
  test_infer "(0 0)" "x => x"
  # container
  test_infer "list[0]" "[]"
  test_infer "list[int]" "[1]"
  # property access
  test_infer "int" "[].size"
  # single operator
  test_infer "bool" "!true"
  # binary operators
  test_infer "int" "1 + 2"
  ### definition
  ##test_infer "int" "a = 1"
  ##test_infer "(1 1)" "f a = a"
  ### function call
  ##test_infer "(int)" "f = () => 1"
  ##test_infer "int" "f = () => 1\nf()"
  ### method call
  ##test_infer "list[int]" "[1].map(x => x + 1)"
  ### index access
  ##test_infer "int" "[1][0]"
  ### steps
  ##test_infer "int" "true\n1"
  # combinations
  #test_infer "f x = x + 1\n(= g x (+ x 2))\n(+ (f 1) (g 1))" "int"
  #test_infer "_ f g x = g (f x)" "((1 2) (2 3) 1 3)"
  #test_infer "_ x y z = x z (y z)" "((1 2 3) (1 2) 1 3)"
  #test_infer "_ b x = if (x b) x (= _ x b)" "(1 (1 bool) (1 1))"
  #test_infer "_ x = if true x (if x true false)" "(bool bool)"
  #test_infer "_ x y = if x x y" "(bool bool bool)"
  #test_infer "_ n = (_ x = (x (_ y = y))) (_ f = f n)" "(1 1)"
  #test_infer "_ x y = x y" "((1 2) 1 2)"
  #test_infer "_ x y = x (y x)" "((1 2) ((1 2) 1) 2)"
  #test_infer "_ h t f x = f h (t f x)" "(1 ((1 2 3) 4 2) (1 2 3) 4 3)"
  #test_infer "_ x y = x (y x) (y x)" "((1 1 2) ((1 1 2) 1) 2)"
  #test_infer "id x = x\nf y = id (y id)" "(((1 1) 2) 2)"
  #test_infer "f x = x\ng = if (f true) (f 1) (f 2)" "int"
  #test_infer "f x = 3\ng = (f true) + (f 4)" "int"
  #test_infer "f x = x\ng y = y\nh b = if b (f g) (g f)" "(bool (1 1))"
  #test_infer "g1 x = x f\ng2 x = x f\nh b f z = if b (g1 z g2) (g2 z g1)" "(bool 1 (1 ((1 2) 2) 3) 3)"
  ## recursive
  #test_infer "f x = (f x)" "(1 2)"
  # type errors
  #reject("(+ 1 true)")

  log "ok"
